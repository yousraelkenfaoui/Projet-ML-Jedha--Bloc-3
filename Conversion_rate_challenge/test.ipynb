{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\" alt=\"DSW LOGO\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# Challenge : predict conversions 🏆🏆\n",
    "\n",
    "This is the template that shows the different steps of the challenge. In this notebook, all the training/predictions steps are implemented for a very basic model (logistic regression with only one variable). Please use this template and feel free to change the preprocessing/training steps to get the model with the best f1-score ! May the force be with you 🧨🧨  \n",
    "\n",
    "**For a detailed description of this project, please refer to *02-Conversion_rate_challenge.ipynb*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings\n",
    "\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "# Read file with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM0feCss5sLZ"
   },
   "outputs": [],
   "source": [
    "# The dataset is quite big : you must create a sample of the dataset before making any visualizations !\n",
    "data_sample = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 284580\n",
      "\n",
      "Number of columns : 6\n",
      "\n",
      "Display of dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>160124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.564203</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873252</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.266789</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.341995</td>\n",
       "      <td>0.176685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country            age       new_user  source  total_pages_visited  \\\n",
       "count   284580  284580.000000  284580.000000  284580        284580.000000   \n",
       "unique       4            NaN            NaN       3                  NaN   \n",
       "top         US            NaN            NaN     Seo                  NaN   \n",
       "freq    160124            NaN            NaN  139477                  NaN   \n",
       "mean       NaN      30.564203       0.685452     NaN             4.873252   \n",
       "std        NaN       8.266789       0.464336     NaN             3.341995   \n",
       "min        NaN      17.000000       0.000000     NaN             1.000000   \n",
       "25%        NaN      24.000000       0.000000     NaN             2.000000   \n",
       "50%        NaN      30.000000       1.000000     NaN             4.000000   \n",
       "75%        NaN      36.000000       1.000000     NaN             7.000000   \n",
       "max        NaN     123.000000       1.000000     NaN            29.000000   \n",
       "\n",
       "            converted  \n",
       "count   284580.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.032258  \n",
       "std          0.176685  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country                0.0\n",
       "age                    0.0\n",
       "new_user               0.0\n",
       "source                 0.0\n",
       "total_pages_visited    0.0\n",
       "converted              0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(data.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Number of columns : {}\".format(data.shape[1]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(data.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = data.describe(include='all')\n",
    "display(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100*data.isnull().sum()/data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "# Make your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPh1qPTf3wZU"
   },
   "source": [
    "## Choose variables to use in the model, and create train and test sets\n",
    "**From the EDA, we know that the most useful feature is total_pages_visited. Let's create a baseline model by using at first only this feature : in the next cells, we'll make preprocessings and train a simple (univariate) logistic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjEHMGoY3kMB"
   },
   "outputs": [],
   "source": [
    "features_list = ['country','age','new_user','source','total_pages_visited']\n",
    "target_variable = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SV5E9KMs4xcq",
    "outputId": "9d1ed76e-e82e-45e7-f3e5-6d47962caa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['country', 'age', 'new_user', 'source', 'total_pages_visited'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b_aU7ij7K3Q"
   },
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_9bEZ5bn7I5Z",
    "outputId": "ad5c8f97-2d25-4827-f1ee-43c665a97fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done!\n",
      "[[ 0.          0.          0.          1.          0.         -0.91516278\n",
      "  -1.47729174 -0.26070136]\n",
      " [ 0.          0.          1.          1.          0.         -0.67320988\n",
      "   0.67691437  0.93728655]\n",
      " [ 0.          0.          1.          0.          1.          0.17362526\n",
      "   0.67691437 -0.85969532]\n",
      " [ 0.          0.          1.          0.          1.          0.7785075\n",
      "   0.67691437 -0.56019834]\n",
      " [ 0.          1.          0.          1.          0.         -0.79418633\n",
      "   0.67691437 -0.26070136]]\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "numeric_features = ['age','new_user','total_pages_visited']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "categorical_features = ['country','source']\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),    \n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "print(\"...Done!\")\n",
    "print(X_train[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1qhidLbq7o-5",
    "outputId": "6bfb746c-1ff4-41c9-b0d6-a98fd09a444d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression() \n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Au2TK_vw7rD-",
    "outputId": "702789a8-4631-4c29-f297-e4b2901f3195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TY_v9uH_CE7"
   },
   "source": [
    "## Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "ngOSdG6-_Cvb",
    "outputId": "1e19e8ee-222f-413b-9bc0-e9f41dcca1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.          0.          1.          0.          0.         -1.27809213\n",
      "   0.67691437  0.63778957]\n",
      " [ 0.          0.          1.          0.          1.          0.05264881\n",
      "   0.67691437  0.03879562]\n",
      " [ 0.          0.          1.          0.          1.         -0.31028053\n",
      "  -1.47729174 -0.26070136]\n",
      " [ 1.          0.          0.          0.          0.         -0.67320988\n",
      "   0.67691437 -0.26070136]\n",
      " [ 0.          0.          1.          0.          0.          1.62534265\n",
      "  -1.47729174  0.63778957]]\n"
     ]
    }
   ],
   "source": [
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "QS1XrzzE_jQI",
    "outputId": "866a96d2-4180-4bd1-ce54-ba052e75d485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxJCTlz0_2it"
   },
   "source": [
    "## Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6x7p1nyr_3UV",
    "outputId": "8e5b91ba-ca06-4486-d808-37a6aaaa8cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.7640404040404042\n",
      "f1-score on test set :  0.7562828755113967\n"
     ]
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "KhDTCeBy__JK",
    "outputId": "72c82d66-d765-437e-e9ef-4ccc80e7183f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on train set : \n",
      "[[246945    954]\n",
      " [  2550   5673]]\n",
      "\n",
      "Confusion matrix on test set : \n",
      "[[27394   107]\n",
      " [  310   647]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our baseline model reaches a f1-score of almost 70%. Now, feel free to refine your model and try to beat this score ! 🚀🚀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tVVDRABv91O"
   },
   "source": [
    "# Train best classifier on all data and use it to make predictions on X_without_labels\n",
    "**Before making predictions on the file conversion_data_test.csv, let's train our model on ALL the data that was in conversion_data_train.csv. Sometimes, this allows to make tiny improvements in the score because we're using more examples to train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "M14RHUadzE2p",
    "outputId": "abcfcfec-9461-4579-adbd-f23270f984eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "X = np.append(X_train,X_test,axis=0)\n",
    "Y = np.append(Y_train,Y_test)\n",
    "\n",
    "classifier.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tr4CEaPzzbP-",
    "outputId": "f0d1c8ed-be4b-4974-d7b9-f23a49344d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n",
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['UK' 28 0 'Seo' 16]\n",
      " ['UK' 22 1 'Direct' 5]\n",
      " ['China' 32 1 'Seo' 1]\n",
      " ['US' 32 1 'Ads' 6]\n",
      " ['China' 25 0 'Seo' 3]]\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "features_list = ['country','age','new_user','source','total_pages_visited']\n",
    "X_without_labels = data_without_labels.loc[:, features_list]\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_without_labels = X_without_labels.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "LoUISfsT0HMR",
    "outputId": "e42dc389-5e77-4e13-ccbc-1fef4aa2c0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ready_batches\u001b[38;5;241m.\u001b[39mget(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# CHECK YOU ARE USING X_without_labels\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding categorical features and standardizing numerical features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m X_without_labels \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_without_labels)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_without_labels[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m,:])\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:800\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 800\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[0;32m    801\u001b[0m     X,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    803\u001b[0m     _transform_one,\n\u001b[0;32m    804\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    805\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    652\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    654\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    659\u001b[0m         delayed(func)(\n\u001b[0;32m    660\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m    661\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    662\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    663\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    664\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    665\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    666\u001b[0m         )\n\u001b[0;32m    667\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:661\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    652\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    654\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    659\u001b[0m         delayed(func)(\n\u001b[0;32m    660\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m--> 661\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    662\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    663\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    664\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    665\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    666\u001b[0m         )\n\u001b[0;32m    667\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:348\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a 2D NumPy array, 2D sparse matrix or pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe when indexing the columns (i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis=1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimension(s).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(X), X\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m indices_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas DataFrames\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "\u001b[1;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "# WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# CHECK YOU ARE USING X_without_labels\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_without_labels = preprocessor.transform(X_without_labels)\n",
    "print(\"...Done\")\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuWSEHuwEQJ"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'UK'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions and dump to file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# where [name] is the name of your team/model separated by a '-'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# For example : [name] = AURELIE-model1\u001b[39;00m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted\u001b[39m\u001b[38;5;124m'\u001b[39m: classifier\u001b[38;5;241m.\u001b[39mpredict(X_without_labels)\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m Y_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted\u001b[39m\u001b[38;5;124m'\u001b[39m],data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     11\u001b[0m Y_predictions\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversion_data_test_predictions_EXAMPLE.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    397\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yousr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'UK'"
     ]
    }
   ],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "data = {\n",
    "    'converted': classifier.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_EXAMPLE.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the coefficients and interpreting the result\n",
    "**In this template, we just trained a model with only one feature (total_pages_visited), so there's no analysis to be done about the feature importance 🤔**\n",
    "\n",
    "**Once you've included more features in your model, please take some time to analyze the model's parameters and try to find some lever for action to improve the newsletter's conversion rate 😎😎**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
